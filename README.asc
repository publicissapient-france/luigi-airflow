# Execution Environments

FIXME : simplifier l'utilisation d'anaconda dans les différents environnements virtuels

## Preamble

These tools and instructions aims to get `Luigi` and `Airflow` complete
working environments easily.

## Pre-requisites

- Docker and docker compose
- Anaconda 3 installer downloaded : https://repo.continuum.io/archive/Anaconda3-4.3.1-Linux-x86_64.sh

## Airflow

There are three main ways to setup airflow, `Sequential Executor`, `Local Executor`
and `Celery Executor`.

For Local Executor and Celery Executor, you will use the files
`docker-compose-LocalExecutor.yml` `docker-compose-CeleryExecutor.yml` that are present
in the `docker` directory of this repository.

### Environment variables

For all of these, please first create a directory that will be the place where you
will place your DAGs source files :

```
export AIRFLOW_DAGS=$HOME/docker/volumes/airflow-dags
mkdir -p $AIRFLOW_DAGS
```

- Create an environment variable `LOVE_MATCHER_PROJECT` that points out to your
love_matcher project (branch master)
- Copy your version of anaconda installer into `docker/docker-airflow/script`

*Warning :* To be able to make work properly the next steps, you should make the
environment variables persistent by editing, for instance, your `.bashrc` file

### Airflow - Sequential Executor

```
docker run -d -p 8079:8080 -v $AIRFLOW_DAGS:\
/usr/local/airflow/dags -v $LOVE_MATCHER_PROJECT:\
/usr/local/airflow/love_matcher_project --name airflow-seq puckel/docker-airflow
```

Go to http://localhost:8079 to check whether airflow runs properly.

### Airflow - Local Executor

Pour démarrer airflow en mode Local Executor avec une base de données
postgres :

```
docker-compose -f docker-compose-LocalExecutor.yml up -d
```

Il faut ensuite installer l'environnement Anaconda nécessaire à l'exécution du projet
`love_matcher` :

```
docker exec -i -t airflow-local /bin/bash
anaconda/Anaconda2-4.3.0-Linux-x86_64.sh
```

suivre la procédure d'installation jusqu'au bout avec les paramètres par défaut puis :

```
exit
docker exec -i -t airflow-local /bin/bash
pip install -e /usr/local/airflow/love_matcher_project
```

il faut ensuite effectuer la configuration des connexions dans `Admin > Connections`. Dans
chacun des paramètres encadrés en rouge dans l'image ci-dessous, entrer les paramètres
suivants :

host : postgres
login : airflow
password : airflow

image::images/connections.png[]

Pour stopper les conteneurs :

```
docker-compose -f docker-compose-LocalExecutor.yml down
```

Tester l'application avec l'url http://localhost:8078

### Airflow - Celery Executor

Pour démarrer airflow en mode Celery Executor avec une base de données
postgres :

```
docker-compose -f docker-compose-CeleryExecutor.yml up -d
```

Pour stopper les conteneurs :

```
docker-compose -f docker-compose-CeleryExecutor.yml down
```

Tester l'application avec l'url http://localhost:8077

## Luigi

- Copy your version of anaconda installer into `docker/docker-luigi/docker/base/scripts`

To startup Luigi containers, you have to go inside `docker/docker-luigi` directory
and then launch `./luigi setup`


## (Optional) Reverse proxies for better experience

### Prerequisites
- Nginx (available with `apt install` or `brew`)

To get a better semantic allowing to experiment the various webserver without having
to remember what localhost:8079 localhost:8078 and localhost:8077 are matching to,
 we suggest to use a reverse proxy to fake local hostnames. In these instructions, we
are going to build it with `/etc/hosts` file and _nginx_.

### Reverse proxies - /etc/hosts

- `sudo vim /etc/hosts`
- add the following lines and save it :
```
127.0.0.1       airflow-seq
127.0.0.1       airflow-loc
127.0.0.1       airflow-cel
127.0.0.1       luigi-scheduler

```
- `sudo service networking restart`

### Reverse proxies - nginx

- `sudo apt install nginx`
- `sudo vim /etc/nginx/conf.d/proxy.conf`
- Write the following content in it :
```
proxy_redirect          off;
proxy_set_header        Host            $host;
proxy_set_header        X-Real-IP       $remote_addr;
proxy_set_header        X-Forwarded-For $proxy_add_x_forwarded_for;
client_max_body_size    10m;
client_body_buffer_size 128k;
client_header_buffer_size 64k;
proxy_connect_timeout   90;
proxy_send_timeout      90;
proxy_read_timeout      90;
proxy_buffer_size   16k;
proxy_buffers       32   16k;
proxy_busy_buffers_size 64k;
```

- Then configure the proxy server :
```
sudo mkdir -p /etc/nginx/backup/sites-enabled
sudo mv /etc/nginx/sites-enabled/default /etc/nginx/backup/sites-enabled/default
sudo vim /etc/nginx/sites-enabled/default
```

- Add the following content to it :
```
server {
        listen   80;
        server_name     airflow-seq;
        location / {
                proxy_pass      http://localhost:8079/;
        }
}

server {
        listen   80;
        server_name     airflow-loc;
        location / {
                proxy_pass      http://localhost:8078/;
        }
}

server {
        listen   80;
        server_name     airflow-cel;
        location / {
                proxy_pass      http://localhost:8077/;
        }
}

server {
        listen   80;
        server_name     luigi-scheduler;
        location / {
                proxy_pass      http://localhost:8082/;
        }
}
```
- Then reload the nginx service with `sudo service nginx reload`
- Test your brand new URL http://airflow-seq !
